---
layout: post
title:  "HashMap详解"
image: ''
description: ''

tags:
- Java
- 源码
- 数据结构
categories:
- Java 基础篇
---
HashMap是Java集合库中一个常用的类，HashMap对应了数据结构中的Hash表，提供常数时间复杂度的查找和修改（这取决于是否发生Hash冲突）。本文将总结HashMap的特点，并从源码角度来理解HashMap的实现原理，并给出一些HashMap的使用建议。
## **特点**
- 实现了Map所有功能，允许值和键为null（这一点和HashTable不同）。
- 当不发生hash冲突时，HashMap提供o(1)时间的get, put等修改操作。
- 由两个参数影响HashMap的性能：
    - initial capacity：capacity是HashMap桶的数量
    - load factor：规定在HashMap达到多少使用率时进行自动扩容成原来桶的2倍。
    
    默认load factor为0.75，这能很好的平衡时间和空间开销。高load factor值将减少空间开销，但是会增加Hash碰撞的概率，从而影响查找的性能。

    应该尽可能减少rehash的次数，当Map初始容量大于(最大实体数/load factor)时，将不会发生rehash。
- 使用拉链法来解决Hash冲突，迭代整个集合耗时是(桶的数量 + 每个桶元素的数量)。所以在注重迭代性能时，不要将初始容量设得太高或Load factor设得太低。
- HashMap不是线程安全的，会fail-fast，在HashMap的迭代器被建立之后，任何对HashMap结构的修改，都会导致抛出ConcurrentModifyException。

## **实现细节**
HashMap存储的元素可以看做一个一个的Key-Value对。在具体实现上，HashMap使用一个固定大小的数组来进行数据存储。数组每个位置对应一个Hash码，因为存在Hash冲突的可能，数组可能存储的不是一个kv对，而是多个key的Hash值相等的kv对。

在Java8之前，HashMap只使用链表来管理冲突的kv对。因此每个数组我们可以看做一个桶，桶存放的是链表的首元素。当查找的某个key发生Hash冲突时，会遍历整个链表。当冲突严重的时候，比如极端情况，桶数组长度为1，那么HashMap就退化成了一个链表。

Java8为了改善发生冲突后的查询性能，引入了红黑树。这样就能够使冲突时的查找性能变为O(logn)，但是树节点比普通链表消耗的内存要多。当冲突的kv对较少的时候，HashMap还是会使用链表。

### **实例域**
```java

// hash表，在第一次使用时被初始化，在必要时候进行扩容
transient Node<K,V>[] table;

// 为keySet()和values()方法提供缓存好的EntrySet
transient Set<Map.Entry<K,V>> entrySet;

// 存储的key-value对的数量
transient int size;

/**
** HashMap结构被改变的次数，结构改变包括改变映射的数量，或者改变内部状态(rehash)
** 用来在遍历Map时，对这个变量进行检查，来实现fail-fast
**/
transient int modCount;

/**
 * 下一次resize的size值，如果没有指定初始是DEFAULT_INITIAL_CAPACITY
**/
int threshold;

/**
 * The load factor for the hash table.
 *
 */
final float loadFactor;
```
HashMap的底层数据结构就是一个数组table，数组存储的元素是Node类型，Node包含两种实现，一种是链表节点，一种是红黑树节点。

modCount是实现fast-fail的关键，它记录了HashMap结构发生改变的次数。

threshold有两种取值的可能：
1. 初始化时等于第一个大于或等于初始capacity的2的n次幂，比如capacity=12，那么threshold=2^4=16。HashMap采用了延迟初始化的方式，在第一次进行put操作时创建数组，长度为threshold。
2. 之后的每次扩容，threshold都等于当前容量capacity * loadFactor。每次HashMap包含的kv对数量size大于threshold时，就会触发扩容。


### **静态域**
HashMap中包含许多静态域，这些域都是一些关键的阈值或初始量，具体介绍如注释中所示。
```java
    // 初始容量，必须是2的倍数，初始是16
    static final int DEFAULT_INITIAL_CAPACITY = 1 << 4; // aka 16

    // 最大容量，必须是2的倍数，其 <= 1 << 30
    static final int MAXIMUM_CAPACITY = 1 << 30;

    // 默认的Load factor
    static final float DEFAULT_LOAD_FACTOR = 0.75f;

    // 链表桶转换为树桶的阈值，当一个桶中元素超过时就将进行转换
    static final int TREEIFY_THRESHOLD = 8;

    // 树桶转换成链表桶的阈值，要小于TREEIFY_THRESHOLD, 在resize分裂桶时，
    // 如果分裂出来的树桶的节点数小于阈值会被重新转化为链表桶
    static final int UNTREEIFY_THRESHOLD = 6;

    /**
    ** 可以进行树桶转换的最小桶数，
    ** 如果没达到，Map会在桶中有超过TREEIFY_THRESHOLD个元素时进行resize。
    ** 一般最少是4*TREEIFY_THRESHOLD 来减少resize和树桶化的阈值间的冲突
    **/
    static final int MIN_TREEIFY_CAPACITY = 64;
```

### **方法**
下面介绍HashMap中的一些关键方法
#### **hash(Object key)**

HashMap计算hashcode的方法是将key的hashcode和hashcode的前16位做^操作。一个key所属桶在桶数组中的下标是hash(key) & (size - 1)
```java
    static final int hash(Object key) {
    int h;
    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}
```

#### **resize()**
HashMap在resize方法中实现了对桶数组的扩容，每次扩容都变为原来数组长度的两倍的两倍。扩容时会将原桶分裂为2个桶（分为树桶分裂和链表桶分裂），过程具体分析见下面代码注释。
    
```java
final Node<K,V>[] resize() {
    // 得到原表
    Node<K,V>[] oldTab = table;
    int oldCap = (oldTab == null) ? 0 : oldTab.length; // 原表容量
    int oldThr = threshold; // 原扩容阈值
    int newCap, newThr = 0; // 新容量，下次扩容的阈值
    
    // 计算新的扩容阈值和容量
    if (oldCap > 0) { // 原容量大于0，进行正常的扩容
        if (oldCap >= MAXIMUM_CAPACITY) { // 已经达到容量上限
            threshold = Integer.MAX_VALUE;
            return oldTab;
        }
        else if ((newCap = oldCap << 1) < MAXIMUM_CAPACITY &&
                 oldCap >= DEFAULT_INITIAL_CAPACITY) // 正常扩容，容量和扩容阈值都是原来2倍
            newThr = oldThr << 1; // double threshold
    }
    else if (oldThr > 0) // 原容量小于等于0，进行延迟初始化，容量等于threshold
        newCap = oldThr;
    else {               // zero initial threshold signifies using defaults
        newCap = DEFAULT_INITIAL_CAPACITY;
        newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);
    }
    
    // 设置新的扩容阈值为 newCap * loadFactor
    if (newThr == 0) {
        float ft = (float)newCap * loadFactor; 
        newThr = (newCap < MAXIMUM_CAPACITY && ft < (float)MAXIMUM_CAPACITY ?
                  (int)ft : Integer.MAX_VALUE);
    }
    
    // 指定下次扩容szie的目标值
    threshold = newThr;
    
    // 创建新size的桶数组，并将HashMap的通数组引用指向它
    @SuppressWarnings({"rawtypes","unchecked"})
        Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap];
    table = newTab;
    
    // 如果原来桶不为空，对所有元素进行rehash和复制
    if (oldTab != null) {
        for (int j = 0; j < oldCap; ++j) {
            Node<K,V> e;
            if ((e = oldTab[j]) != null) {
                oldTab[j] = null;
                // 桶只有一个元素
                if (e.next == null)
                    newTab[e.hash & (newCap - 1)] = e;
                // 如果是TreeNode，调用TreeNode#split方法进行树桶的分裂
                else if (e instanceof TreeNode)
                    ((TreeNode<K,V>)e).split(this, newTab, j, oldCap);
                else { // preserve order
                /**
                ** 如果是链表桶，将每个桶分裂成2个桶，将原桶元素重新加入到各桶中去
                **/
                    Node<K,V> loHead = null, loTail = null;
                    Node<K,V> hiHead = null, hiTail = null;
                    Node<K,V> next;
                    do {
                        next = e.next;
                        if ((e.hash & oldCap) == 0) {
                            if (loTail == null)
                                loHead = e;
                            else
                                loTail.next = e;
                            loTail = e;
                        }
                        else {
                            if (hiTail == null)
                                hiHead = e;
                            else
                                hiTail.next = e;
                            hiTail = e;
                        }
                    } while ((e = next) != null);
                    if (loTail != null) {
                        loTail.next = null;
                        newTab[j] = loHead;
                    }
                    if (hiTail != null) {
                        hiTail.next = null;
                        newTab[j + oldCap] = hiHead;
                    }
                }
            }
        }
    }
    return newTab;
}
```
#### **treeifyBin()**
将一个链表桶转变成树桶，为了提高HashMap在Hash冲突时的查找性能，当某个桶中的容量大于TREEIFY_THRESHOLD时会触发链表桶转树桶。

这里存在一个限制，如果桶数组的长度小于MIN_TREEIFY_CAPACITY，那么会触发数组的扩容，而不是将当前的桶转换为树桶。

```java
final void treeifyBin(Node<K,V>[] tab, int hash) {
    int n, index; Node<K,V> e;
    // 如果桶数组的长度小于MIN_TREEIFY_CAPACITY，只进行扩容
    if (tab == null || (n = tab.length) < MIN_TREEIFY_CAPACITY)
        resize();
    // 否则将桶中每个节点变为TreeNode
    else if ((e = tab[index = (n - 1) & hash]) != null) {
        TreeNode<K,V> hd = null, tl = null;
        do {
            TreeNode<K,V> p = replacementTreeNode(e, null);
            if (tl == null)
                hd = p;
            else {
                p.prev = tl;
                tl.next = p;
            }
            tl = p;
        } while ((e = e.next) != null);
        
        // 建树
        if ((tab[index] = hd) != null)
            hd.treeify(tab);
    }
}
    ```
#### **put()**
- 如果某个桶的节点数大于树转换阈值TREEIFY_THRESHOLD会进行链表向红黑树的转换。
- 如果桶数组为空，或者加入key-value对后，MAP的size大于阈值，会进行扩容。
```java
public V put(K key, V value) {
    return putVal(hash(key), key, value, false, true);
}
final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
               boolean evict) {
    
    Node<K,V>[] tab; Node<K,V> p; int n, i;
    // 如果表为空或长度为0，就进行resize
    if ((tab = table) == null || (n = tab.length) == 0)
        n = (tab = resize()).length;
        
    // 如果key所对应的桶为空，直接将key作为头元素插入
    if ((p = tab[i = (n - 1) & hash]) == null)
        tab[i] = newNode(hash, key, value, null);
        
    // 否则，发生hash碰撞
    else {
        Node<K,V> e; K k;
        // 如果桶中首元素的key和要插入的key-value对的key相等，就直接更新value值
        if (p.hash == hash &&
            ((k = p.key) == key || (key != null && key.equals(k))))
            e = p;
        // 如果桶是树桶，进行树桶的PutValue操作
        else if (p instanceof TreeNode)
            e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
        else {
        // 否则是链表桶，如果在链表中找到相同的Key就更新value，否则插入到链表的末尾
            for (int binCount = 0; ; ++binCount) {
                if ((e = p.next) == null) {
                    p.next = newNode(hash, key, value, null);
                    
                    // 当桶中元素数量达到树转换阈值时，将链表转换成树
                    if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
                        treeifyBin(tab, hash);
                    break;
                }
                if (e.hash == hash &&
                    ((k = e.key) == key || (key != null && key.equals(k))))
                    break;
                p = e;
            }
        }
        if (e != null) { // existing mapping for key
            V oldValue = e.value;
            if (!onlyIfAbsent || oldValue == null)
                e.value = value;
            afterNodeAccess(e);
            return oldValue;
        }
    }
    // 每一次Put都相当于对HashMap结构进行了修改
    ++modCount;
    // 如果当前容量大于阈值，进行一次扩容
    if (++size > threshold)
        resize();
    afterNodeInsertion(evict);
    return null;
}
```
#### **get()**
get方法的逻辑很简单，先根据key的hashcode & table.length来找到key对应的桶，然后查找桶中元素得到对应的value，或返回null。
```java
public V get(Object key) {
        Node<K,V> e;
        return (e = getNode(hash(key), key)) == null ? null : e.value;
    }

final Node<K,V> getNode(int hash, Object key) {
    Node<K,V>[] tab; Node<K,V> first, e; int n; K k;
    
    if ((tab = table) != null && (n = tab.length) > 0 &&
        (first = tab[(n - 1) & hash]) != null) {
        // 检查桶头元素是否为要查找的元素， 是就返回其value
        if (first.hash == hash && // always check first node
            ((k = first.key) == key || (key != null && key.equals(k))))
            return first;
        // 查找桶中的元素，看是否能找到对应的Key，链表O(n)，树o(log n)
        if ((e = first.next) != null) {
            if (first instanceof TreeNode)
                return ((TreeNode<K,V>)first).getTreeNode(hash, key);
            do {
                if (e.hash == hash &&
                    ((k = e.key) == key || (key != null && key.equals(k))))
                    return e;
            } while ((e = e.next) != null);
        }
    }
    // 如果桶数组对应位置为null，说明key不在Map中，直接返回NULL
    return null;
}
```
#### **remove()**
删除操作逻辑很简单，通过key的hashcode查找到对应的桶，在桶中查找到对应的kv对，然后删除。
```java
final Node<K,V> removeNode(int hash, Object key, Object value,
                               boolean matchValue, boolean movable) {
    Node<K,V>[] tab; Node<K,V> p; int n, index;

    if ((tab = table) != null && (n = tab.length) > 0 &&
        (p = tab[index = (n - 1) & hash]) != null) {
        /** 查找对应key的kv对，最终node指向对应的节点（链表或树节点），如果node是链表节点
        **  p指向node的父节点或p为首节点(node为首节点时)
        **/
        Node<K,V> node = null, e; K k; V v;
        if (p.hash == hash &&
            ((k = p.key) == key || (key != null && key.equals(k))))
            node = p;
        else if ((e = p.next) != null) {
            if (p instanceof TreeNode) // 在树中查找
                node = ((TreeNode<K,V>)p).getTreeNode(hash, key);
            else { // 遍历链表查找
                do {
                    if (e.hash == hash &&
                        ((k = e.key) == key ||
                         (key != null && key.equals(k)))) {
                        node = e;
                        break;
                    }
                    p = e;
                } while ((e = e.next) != null);
            }
        }
        // 查找到node，删除node
        if (node != null && (!matchValue || (v = node.value) == value ||
                             (value != null && value.equals(v)))) {
            if (node instanceof TreeNode) // 树中删除
                ((TreeNode<K,V>)node).removeTreeNode(this, tab, movable);
            // 从链表中删除node
            else if (node == p)
                tab[index] = node.next;
            else 
                p.next = node.next;
            ++modCount;
            --size;
            afterNodeRemoval(node);
            return node;
        }
    }
    return null;
}
```
#### **EntrySet，Vlues, KeySet**
Map有三个内部类，分别作为它在不同角度的视图。对这些视图的操作会直接影响Map。可以通过HashMap的entrySet()、values()和keySets()分别得到上述的三种视图。

前面提到过，对HashMap进行遍历时不允许并发的进行修改。对这三个视图的遍历也遵循这个规则。这三个视图返回的迭代器分别是KeyIterator、ValueInterator和EntryIterator，它们都继承了HashIterator，并通过模板方法模式调用了HashIterator#nextNode()方法。

每次调用nextNode()都会通过判断HashMap的modCount是否依然和建立Iterator时的值相等，不相等就触发fail-fast机制，抛出ConcurrentModificationException。这就是Java集合类中使用Iterator遍历fail-fast的通用实现方法。


```java
final class KeyIterator extends HashIterator
    implements Iterator<K> {
    public final K next() { return nextNode().key; }
}

final class ValueIterator extends HashIterator
    implements Iterator<V> {
    public final V next() { return nextNode().value; }
}

final class EntryIterator extends HashIterator
    implements Iterator<Map.Entry<K,V>> {
    public final Map.Entry<K,V> next() { return nextNode(); }
}

// HashIterator

final Node<K,V> nextNode() {
    Node<K,V>[] t;
    Node<K,V> e = next;
    if (modCount != expectedModCount) // 判断在遍历期间，HashMap是否发生结构上的修改
        throw new ConcurrentModificationException();
    if (e == null)
        throw new NoSuchElementException();
    if ((next = (current = e).next) == null && (t = table) != null) {
        do {} while (index < t.length && (next = t[index++]) == null);
    }
    return e;
}
```
值得注意的时，不只是通过迭代器，Java8引入的forEach()操作同样也会抛出ConcurrentModificationException。   

### **一些问题**
#### **什么样的操作会修改modCount**
我们都知道，fail-fast机制使用modCount来记录HashMap结构改变的次数。但是我有点迷惑，到底什么操作会修改modCount。于是我进行了统计，统计基于Jdk 1.8。
- putVal：put方法调用，不管是插入还是修改。
- removeNode：当删除的key存在时。
- clear：调用clear就会修改，无论是Map是否包含元素，或是否初始化。
- computeIfPresent/computeIfAbsent/compute：根据原key-value对和给定的mappingFunction计算新value值，每次调用都会修改modCount。

#### **HashMap在并发扩容时会出现死循环**
HashMap不是线程安全的，可能在高并发的环境下同时发生扩容，导致死循环。具体问题分析可以参见[不正当使用HashMap导致cpu 100%的问题追究](http://ifeve.com/hashmap-infinite-loop/)

#### **Hash计算方法**
计算Hash值的方法有很多，方法细节会在另一篇文章中提到。

#### **Hash冲突的解决方法**
解决Hash冲突的方法有多种，常见的有HashMap采用的拉链法和开放寻址法。

开放寻址法将所有元素都存放在Hash表中，当查找某个key时，会按某种探查顺序检查表中各项，直到找到或确定元素不存在于表中。常见的探查方法有线性探查、二次探查和多重散列等（具体可参见[算法导论](https://book.douban.com/subject/20432061/)）。

#### **HashMap与HashTable的区别**
- HashMap 线程不安全， HashTable线程安全（sync）
- HashMap允许null的key和value，HashTable不能使用null
- HashMap有containsKye和containsValue, HashTable只有contains
- 两个使用的hash方法不同：
    - HashMap: (h = key.hashCode()) ^ (h >>> 16);
    - HashTable:index = (hash & 0x7FFFFFFF) % tab.length;
- HashMap有两种桶（树桶和链表桶），HashTable只有一种。
- HashMap继承AbstractMap,Hashtable继承Dictionary类。
- HashMap和Hashtable的Iterator都是fail-fast的，但是Hashtable的Enumerator不是fail-fast的。
